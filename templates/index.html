<!DOCTYPE html>
<html lang="es">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Unidad 7403</title>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <head>
  <link rel="stylesheet" href="styles/style.css">
</head>
  <link
    href="https://fonts.googleapis.com/css2?family=Archivo:ital,wght@0,100..900;1,100..900&family=Bowlby+One&family=Kode+Mono:wght@400..700&family=Noto+Sans&display=swap"
    rel="stylesheet">


</head>

<body>
  <!-- Contenedor principal de la página (utiliza Grid) -->

  <!-- Sección Superior Izquierda: Título "7403" y su línea -->
  <div class="top-left-header">
    <h1>7403</h1>
    <div class="title-underline"></div>
  </div>

  <!-- Sección Superior Derecha: Aquí va el estado -->
  <div class="top-right-status">
    <p id="estado">Comenzar</p>
  </div>
  <div class="scene">
    <div class="wrapper">
      <div class="globe">
        <span class="ring"></span>
        <span class="ring"></span>
        <span class="ring"></span>
        <span class="ring"></span>
        <span class="ring"></span>
        <span class="ring"></span>
        <span class="ring"></span>
      </div>
    </div>
  </div>
  <!-- Sección Media Izquierda: Canvas del visualizador de audio -->
  <canvas id="canvas"></canvas>

  <!-- Sección Media Derecha: Párrafos de respuesta (Estado ya no está aquí) -->
  <div class="middle-right-content">
    <p id="respuesta">Respuesta</p>
    <div class="loader">
      <div class="part">
        <div class="part">
          <div class="part">
            <div class="part">
              <div class="part"></div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Sección Inferior Izquierda: Salida de la consola de Python -->
  <div id="console-output">Consola de Python lista.</div>

  <!-- Sección Inferior Derecha: Botón "Activar" -->
  <div class="bottom-right-button">
    <button onclick="iniciarConversacion()">Activar</button>
  </div>

  <!-- Elemento de audio (oculto visualmente) -->
  <audio id="audio"></audio>

  <script>
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");

    // Función para redimensionar el canvas y asegurar que el visualizador funcione correctamente
    function resizeCanvas() {
      canvas.width = canvas.offsetWidth; // Ajusta el ancho del canvas a su ancho renderizado por CSS
      canvas.height = canvas.offsetHeight; // Ajusta el alto del canvas a su alto renderizado por CSS
      if (initialized) { // Solo redibujar si ya se ha inicializado el visualizador
        visualizar();
      }
    }

    // Ejecutar resizeCanvas al cargar la página y al cambiar el tamaño de la ventana
    window.addEventListener('load', resizeCanvas);
    window.addEventListener('resize', resizeCanvas);

    let audioContext, analyser, freqs, mediaStream;
    let recognition;
    let isListening = false;
    let initialized = false;
    const WAKE_WORD = "robot";
    let processingResponse = false;

    // Referencia al elemento de salida de la consola
    const consoleOutputEl = document.getElementById("console-output");

    // Inicializa el texto de la consola al cargar la página
    consoleOutputEl.textContent = "Consola de Python esperando por información.\n";

    // Función para iniciar el reconocimiento de voz
    function startRecognition() {
      if (!recognition) {
        recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = 'es-ES'; // Idioma español
        recognition.interimResults = false; // Solo resultados finales
        recognition.maxAlternatives = 1; // Solo la mejor alternativa
        //recognition.continuous = true; // Solo la mejor alternativa
        recognition.onstart = () => {
          console.log("onstart!!!!!!!!!")
          isListening = true;
          document.getElementById("estado").textContent = "Llámame por mi nombre 'robot'";
          // document.getElementById("respuesta").textContent = ""; // COM-01: Eliminado/comentado para mantener la respuesta anterior
        };

        recognition.onresult = (event) => {
          const transcript = event.results[0][0].transcript.toLowerCase().trim();
          document.getElementById("estado").textContent = `Escuchaste: "${transcript}"`;

          if (transcript.includes(WAKE_WORD)) {
            const command = transcript.replace(WAKE_WORD, '').trim();
            document.getElementById("estado").textContent = `¡Activado! Enviando: "${command}"`;
            recognition.stop(); // Detener el reconocimiento para procesar
            isListening = false;
            enviarMensaje(command);
          } else {
            document.getElementById("estado").textContent = "Esperando escuchar palabra de activación...";
          }
        };
        recognition.onerror = (event) => {
          console.error("Error en SpeechRecognition:", event.error);
          document.getElementById("estado").textContent = `Error: ${event.error}. Reiniciando...`;
          isListening = false;
          setTimeout(startRecognition, 5000); // Intentar reiniciar después de 1 segundo
        };

        recognition.onend = () => {
          console.log("onend!!!!!!!!!!")
          isListening = false;
          // Reiniciar el reconocimiento solo si no estamos procesando una respuesta
          if (!processingResponse) startRecognition();
        };
      }

      // Iniciar el reconocimiento si no está escuchando
      if (!isListening) {
        try {
          recognition.start();
        } catch (e) {
          console.warn("SpeechRecognition ya estaba activo:", e);
          isListening = true; // Asegurarse de que el estado esté correcto
        }
      }
    }

    // Función para inicializar el sistema (micrófono y visualizador)
    async function iniciarConversacion() {
      if (initialized) {
        document.getElementById("estado").textContent = "El sistema ya está activo.";
        return;
      }

      document.getElementById("estado").textContent = "Activando micrófono y visualizador...";
      initialized = true;
      // Ocultar el botón "Activar"
      const activateButton = document.querySelector('.bottom-right-button button');
      if (activateButton) {
        activateButton.style.display = 'none'; // Esto ocultará el botón
      }

      document.getElementById("estado").textContent = "Activando micrófono y visualizador...";
      initialized = true;
      // Solicitar pantalla completa
      if (document.documentElement.requestFullscreen) {
        document.documentElement.requestFullscreen();
      } else if (document.documentElement.mozRequestFullScreen) { /* Firefox */
        document.documentElement.mozRequestFullScreen();
      } else if (document.documentElement.webkitRequestFullscreen) { /* Chrome, Safari & Opera */
        document.documentElement.webkitRequestFullscreen();
      } else if (document.documentElement.msRequestFullscreen) { /* IE/Edge */
        document.documentElement.msRequestFullscreen();
      }

      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true }); // Acceder al micrófono
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256; // Tamaño del FFT para el análisis de frecuencia
        freqs = new Uint8Array(analyser.frequencyBinCount); // Array para almacenar los datos de frecuencia
        const source = audioContext.createMediaStreamSource(mediaStream);
        source.connect(analyser); // Conectar la fuente de audio al analizador
        visualizar(); // Iniciar la visualización
        startRecognition(); // Iniciar el reconocimiento de voz
      } catch (error) {
        console.error("Error al acceder al micrófono:", error);
        document.getElementById("estado").textContent = "Error al acceder al micrófono.";
      }
    }

    // Función para dibujar el visualizador de audio en el canvas
    function visualizar() {
      requestAnimationFrame(visualizar); // Repetir la animación en cada frame
      analyser.getByteFrequencyData(freqs); // Obtener los datos de frecuencia
      ctx.fillStyle = "#000"; // Fondo negro del canvas
      ctx.fillRect(0, 0, canvas.width, canvas.height); // Limpiar el canvas
      const barWidth = (canvas.width / freqs.length) * 2.5; // Ancho de cada barra
      let x = 0;
      for (let i = 0; i < freqs.length; i++) {
        const barHeight = freqs[i]; // Altura de la barra basada en la frecuencia
        ctx.fillStyle = "lime"; // Color de las barras (verde neón)
        ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight); // Dibujar la barra
        x += barWidth + 1; // Mover a la siguiente posición
      }
    }

    // Función para enviar el mensaje al backend y reproducir la respuesta
    async function enviarMensaje(message) {
      processingResponse = true; // Indica que se está procesando una respuesta
      const audioEl = document.getElementById("audio");
      const respuestaEl = document.getElementById("respuesta");

      // Añadir un separador y el mensaje de carga a la consola
      consoleOutputEl.textContent += `\n--- Solicitud [${new Date().toLocaleTimeString()}] ---\n`;
      consoleOutputEl.textContent += `Cargando salida de consola...\n`;
      consoleOutputEl.scrollTop = consoleOutputEl.scrollHeight; // Desplazar al final

      audioEl.src = ""; // Limpiar el audio anterior
      respuestaEl.textContent = "Procesando respuesta..."; // Esta línea se ejecutará al recibir una nueva solicitud y sobrescribirá la respuesta anterior
      document.getElementById("estado").textContent = "Pensando...";

      try {
        // Aquí se realiza la llamada al backend. Asegúrate de que tu servidor Python esté corriendo.
        const res = await fetch('http://127.0.0.1:5000/api/robot', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ mensaje: message })
        });

        const data = await res.json();
        console.log("Respuesta del backend:", data);
        respuestaEl.textContent = data.respuesta || "Sin respuesta textual del asistente.";

        // Si el backend envía un campo 'console_output', lo mostramos
        if (data.console_output) {
          consoleOutputEl.textContent += `Salida de Python:\n${data.console_output}\n`;
        } else {
          consoleOutputEl.textContent += `No se recibió salida específica de la consola.\n`;
        }
        consoleOutputEl.scrollTop = consoleOutputEl.scrollHeight; // Desplazar al final

        if (data.audio_url) {
          audioEl.src = `http://127.0.0.1:5000${data.audio_url}`;
          audioEl.play();
          document.getElementById("estado").textContent = "Escúchame";
          // Cuando el audio termina, reiniciar el reconocimiento
          audioEl.onended = () => {
            console.log("Audio de respuesta finalizado.");
            processingResponse = false;
            startRecognition();
          };
        } else {
          processingResponse = false;
          startRecognition(); // Reiniciar el reconocimiento si no hay audio
        }
      } catch (err) {
        console.error("Error al comunicarse con el backend:", err);
        respuestaEl.textContent = `Ocurrió un error: ${err.message}`;
        document.getElementById("estado").textContent = "Error de comunicación.";
        consoleOutputEl.textContent += `Error de conexión: ${err.message}\n`; // Mostrar error en la consola también
        consoleOutputEl.scrollTop = consoleOutputEl.scrollHeight; // Desplazar al final
        processingResponse = false;
        startRecognition(); // Reiniciar el reconocimiento en caso de error
      }
    }

    // Manejo de la visibilidad de la pestaña para detener/reiniciar el reconocimiento
    document.addEventListener("visibilitychange", () => {
      if (document.visibilityState === "visible") {
        if (!isListening && !processingResponse && initialized) {
          setTimeout(startRecognition, 500); // Reiniciar si vuelve a ser visible
        }
      } else {
        if (recognition && isListening) {
          recognition.stop(); // Detener si la pestaña no está activa
          isListening = false;
        }
      }
    });
  </script>
</body>

</html>